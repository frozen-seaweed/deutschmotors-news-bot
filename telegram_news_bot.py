# telegram_news_bot.py
import os, re, requests
from datetime import datetime
from storage import (
    build_keyword_weights,
    load_sent_articles,
    save_sent_articles,
    normalize_url,
)

BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
NEWS_API_KEY = os.getenv("NEWS_API_KEY")

def get_news():
    url = "https://newsapi.org/v2/everything"
    params = {
        "q": "ìë™ì°¨ OR í˜„ëŒ€ì°¨ OR EV OR ë°°í„°ë¦¬ OR ëª¨ë¹Œë¦¬í‹° OR ê¸°ì•„",
        "language": "ko",
        "pageSize": 20,      # ë„‰ë„‰íˆ ê°€ì ¸ì™€ì„œ í•„í„°ë§
        "sortBy": "publishedAt",
        "apiKey": NEWS_API_KEY,
    }
    r = requests.get(url, params=params, timeout=20)
    r.raise_for_status()
    return r.json().get("articles", [])

def score_article(article, keyword_weights):
    text = f"{article.get('title','')} {article.get('description','')}".lower()
    score = 0
    for kw, w in (keyword_weights or {}).items():
        if kw.lower() in text:
            score += int(w) if isinstance(w, int) else 1
    return score

def normalize_title(t: str) -> str:
    t = t or ""
    t = re.sub(r"[\[\](){}â€œâ€\"'â€˜â€™]", "", t)
    t = re.sub(r"\s+", " ", t).strip().lower()
    return t

def send_news(article):
    kb = {"inline_keyboard": [[{"text": "ğŸ‘ ì¢‹ì•„ìš”", "callback_data": f"like:{article['url']}"}]]}
    title = article.get("title","")
    desc  = article.get("description","") or ""
    link  = article.get("url","")
    text = f"ğŸ“° {title}\n\n{desc}\n\n{link}"
    payload = {"chat_id": CHAT_ID, "text": text, "reply_markup": kb}
    r = requests.post(f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage", json=payload, timeout=20)
    r.raise_for_status()

def send_daily_news():
    # 1) ìˆ˜ì§‘
    articles = get_news()

    # 2) ê³¼ê±° ì „ì†¡ ê¸°ë¡(ê¹ƒí—ˆë¸Œ) ë¡œë“œ
    sent_map, sent_sha = load_sent_articles()

    # 3) ì •ê·œí™” ê¸°ë°˜ ì¤‘ë³µ ì œê±° (URL + ì œëª©)
    uniq, seen_urls, seen_titles = [], set(), set()
    for a in articles:
        url = a.get("url")
        title = a.get("title")
        if not url or not title:
            continue

        nurl = normalize_url(url)
        ntit = normalize_title(title)

        if nurl in sent_map:     # ê³¼ê±°ì— ë³´ëƒ„ â†’ ìŠ¤í‚µ
            continue
        if nurl in seen_urls:    # ê°™ì€ ì‹¤í–‰ ë‚´ ì¤‘ë³µ URL â†’ ìŠ¤í‚µ
            continue
        if ntit in seen_titles:  # ê°™ì€ ì‹¤í–‰ ë‚´ ì œëª© ì¤‘ë³µ â†’ ìŠ¤í‚µ
            continue

        seen_urls.add(nurl)
        seen_titles.add(ntit)
        uniq.append(a)

    if not uniq:
        print("No new unique articles.")
        return

    # 4) ì¢‹ì•„ìš” í•™ìŠµ ê°€ì¤‘ì¹˜ ë°˜ì˜í•´ì„œ ì •ë ¬
    kw_weights = build_keyword_weights()
    uniq.sort(key=lambda a: score_article(a, kw_weights), reverse=True)

    # 5) ìƒìœ„ 4ê±´ ì „ì†¡
    picked = uniq[:4]
    for art in picked:
        send_news(art)

    # 6) ì „ì†¡ ê¸°ë¡ ì €ì¥ (ì •ê·œí™” URLì„ í‚¤ë¡œ ì €ì¥)
    now = datetime.utcnow().isoformat() + "Z"
    for art in picked:
        nurl = normalize_url(art.get("url",""))
        if nurl:
            sent_map[nurl] = now
    save_sent_articles(sent_map, sent_sha)

if __name__ == "__main__":
    send_daily_news()
